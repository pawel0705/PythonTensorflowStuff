{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model przerabiający liczbę na rzymską cyfrę\n",
    "- input: number in range(0,DATASE_SIZE)\n",
    "- output: roman number\n",
    "\n",
    "Examples: \n",
    "- input: 10, output: X\n",
    "- input: 6, output: VI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modułów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import RNN, LSTM, RepeatVector\n",
    "from tensorflow.python.keras import layers\n",
    "from encoder import CharacterTable \n",
    "import numpy as np\n",
    "import roman_numerals as cnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdefiniowanie znaków rzymskich i cyfr, utworzenie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 3)                 6         \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 10, 3)             0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 10, 128)           67584     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10, 64)            49408     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10, 8)             520       \n",
      "=================================================================\n",
      "Total params: 117,518\n",
      "Trainable params: 117,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Zdefiniowanie parametrów dla modelu i danych\n",
    "INPUT = 3\n",
    "OUTPUT = 10\n",
    "DATASET_SIZE=200\n",
    "\n",
    "# object to encode roman numbers to one-hot \n",
    "romans = ' MDCLXVI'\n",
    "rtable = CharacterTable(romans)\n",
    "\n",
    "# object to encode arabic numbers to one-hot\n",
    "chars = ' 0123456789'\n",
    "dtable = CharacterTable(chars)\n",
    "\n",
    "# zbudowanie modelu\n",
    "model = Sequential()\n",
    "model.add(Dense(INPUT, input_dim=1)) \n",
    "model.add(RepeatVector(OUTPUT)) #długość wyniku końcowego\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Dense(len(romans),activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utworzenie zbioru danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample (input): 1\n",
      "Label ['I']\n",
      "Label encoded (output):\n",
      " [[0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "(200, 10, 8)\n",
      "(200,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pawel\\anaconda3\\envs\\deep\\lib\\site-packages\\ipykernel_launcher.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "labels = []\n",
    "seq_samples = []\n",
    "seq_labels = []\n",
    "\n",
    "import random\n",
    "\n",
    "for i in range(DATASET_SIZE):\n",
    "    samples.append(i + 1)\n",
    "    seq_samples.append(i + 1)\n",
    "    words = cnv.convert(i + 1)\n",
    "    labels.append(list(words))\n",
    "    seq_labels.append(list(words))\n",
    "\n",
    "samples = np.array(samples)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Sample (input):\",samples[0])\n",
    "print(\"Label\",labels[0])\n",
    "\n",
    "\n",
    "nlabels = np.zeros((DATASET_SIZE,OUTPUT,len(romans)))\n",
    "for i in range(DATASET_SIZE):\n",
    "    for j in range(OUTPUT):\n",
    "        if j>=len(labels[i]): \n",
    "                nlabels[i][j][0]=1\n",
    "                continue\n",
    "        x = labels[i][j]\n",
    "        index = romans.index(x)\n",
    "        nlabels[i][j][index] = 1\n",
    "print(\"Label encoded (output):\\n\",nlabels[123])\n",
    "labels = nlabels\n",
    "print(labels.shape)\n",
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rozdzielenie zbioru danych na dane treningowe i testowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 100  test samples 100\n"
     ]
    }
   ],
   "source": [
    "TRAINING_SIZE = .5\n",
    "from sklearn.model_selection import train_test_split\n",
    "(trainSamples, testSamples, trainLabels, testLabels) = train_test_split(samples, labels,train_size=TRAINING_SIZE,random_state=42)\n",
    "print('Training samples:',len(trainSamples),' test samples',len(testSamples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetwarzanie label na rzymski odpowiednik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -> MMMMMMMMMM  [T]\n",
      "2 -> MMMMMMMMMM  [T]\n",
      "3 -> MMMMMMMMMM  \n",
      "4 -> MMMMMMMMMM  [T]\n",
      "5 -> MMMMMMMMMM  [T]\n",
      "6 -> MMMMMMMMMM  \n",
      "7 -> MMMMMMMM  \n",
      "8 ->   [T]\n",
      "9 ->   [T]\n",
      "10 ->   \n",
      "11 ->   [T]\n",
      "12 ->   \n",
      "13 ->   \n",
      "14 ->   [T]\n",
      "15 ->   [T]\n",
      "16 ->   \n",
      "17 ->   \n",
      "18 ->   [T]\n",
      "19 ->   \n",
      "20 ->   \n",
      "21 ->   [T]\n",
      "22 ->   [T]\n",
      "23 ->   \n",
      "24 ->   [T]\n",
      "25 ->   \n",
      "26 ->   [T]\n",
      "27 ->   \n",
      "28 ->   \n",
      "29 ->   [T]\n",
      "30 ->   \n",
      "31 ->   \n",
      "32 ->   \n",
      "33 ->   [T]\n",
      "34 ->   \n",
      "35 ->   [T]\n",
      "36 ->   \n",
      "37 ->   \n",
      "38 ->   [T]\n",
      "39 ->   \n",
      "40 ->   [T]\n",
      "41 ->   [T]\n",
      "42 ->   \n",
      "43 ->   \n",
      "44 ->   [T]\n",
      "45 ->   [T]\n",
      "46 ->   \n",
      "47 ->   \n",
      "48 ->   [T]\n",
      "49 ->   [T]\n",
      "50 ->   [T]\n",
      "51 ->   [T]\n",
      "52 ->   \n",
      "53 ->   [T]\n",
      "54 ->   [T]\n",
      "55 ->   [T]\n",
      "56 ->   \n",
      "57 ->   \n",
      "58 ->   [T]\n",
      "59 ->   [T]\n",
      "60 ->   [T]\n",
      "61 ->   \n",
      "62 ->   \n",
      "63 ->   [T]\n",
      "64 ->   [T]\n",
      "65 ->   [T]\n",
      "66 ->   \n",
      "67 ->   \n",
      "68 ->   \n",
      "69 ->   \n",
      "70 ->   \n",
      "71 ->   [T]\n",
      "72 ->   [T]\n",
      "73 ->   [T]\n",
      "74 ->   \n",
      "75 ->   [T]\n",
      "76 ->   \n",
      "77 ->   \n",
      "78 ->   \n",
      "79 ->   \n",
      "80 ->   \n",
      "81 ->   [T]\n",
      "82 ->   [T]\n",
      "83 ->   \n",
      "84 ->   [T]\n",
      "85 ->   \n",
      "86 ->   \n",
      "87 ->   \n",
      "88 ->   [T]\n",
      "89 ->   [T]\n",
      "90 ->   [T]\n",
      "91 ->   \n",
      "92 ->   [T]\n",
      "93 ->   [T]\n",
      "94 ->   \n",
      "95 ->   [T]\n",
      "96 ->   \n",
      "97 ->   \n",
      "98 ->   \n",
      "99 ->   \n",
      "100 ->   [T]\n",
      "101 ->   \n",
      "102 ->   \n",
      "103 ->   [T]\n",
      "104 ->   [T]\n",
      "105 ->   \n",
      "106 ->   [T]\n",
      "107 ->   [T]\n",
      "108 ->   [T]\n",
      "109 ->   [T]\n",
      "110 ->   [T]\n",
      "111 ->   [T]\n",
      "112 ->   \n",
      "113 ->   [T]\n",
      "114 ->   \n",
      "115 ->   \n",
      "116 ->   \n",
      "117 ->   [T]\n",
      "118 ->   \n",
      "119 ->   \n",
      "120 ->   \n",
      "121 ->   \n",
      "122 ->   [T]\n",
      "123 ->   \n",
      "124 ->   [T]\n",
      "125 ->   \n",
      "126 ->   \n",
      "127 ->   \n",
      "128 ->   \n",
      "129 ->   \n",
      "130 ->   [T]\n",
      "131 ->   [T]\n",
      "132 ->   [T]\n",
      "133 ->   \n",
      "134 ->   [T]\n",
      "135 ->   [T]\n",
      "136 ->   \n",
      "137 ->   \n",
      "138 ->   \n",
      "139 ->   [T]\n",
      "140 ->   \n",
      "141 ->   \n",
      "142 ->   \n",
      "143 ->   [T]\n",
      "144 ->   \n",
      "145 ->   [T]\n",
      "146 ->   [T]\n",
      "147 ->   [T]\n",
      "148 ->   [T]\n",
      "149 ->   \n",
      "150 ->   [T]\n",
      "151 ->   \n",
      "152 ->   [T]\n",
      "153 ->   \n",
      "154 ->   [T]\n",
      "155 ->   [T]\n",
      "156 ->   [T]\n",
      "157 ->   [T]\n",
      "158 ->   [T]\n",
      "159 ->   \n",
      "160 ->   \n",
      "161 ->   [T]\n",
      "162 ->   \n",
      "163 ->   \n",
      "164 ->   [T]\n",
      "165 ->   \n",
      "166 ->   \n",
      "167 ->   [T]\n",
      "168 ->   [T]\n",
      "169 ->   [T]\n",
      "170 ->   \n",
      "171 ->   \n",
      "172 ->   [T]\n",
      "173 ->   \n",
      "174 ->   \n",
      "175 ->   \n",
      "176 ->   [T]\n",
      "177 ->   [T]\n",
      "178 ->   \n",
      "179 ->   [T]\n",
      "180 ->   [T]\n",
      "181 ->   [T]\n",
      "182 ->   [T]\n",
      "183 ->   \n",
      "184 ->   [T]\n",
      "185 ->   [T]\n",
      "186 ->   [T]\n",
      "187 ->   \n",
      "188 ->   \n",
      "189 ->   [T]\n",
      "190 ->   \n",
      "191 ->   \n",
      "192 ->   \n",
      "193 ->   [T]\n",
      "194 ->   [T]\n",
      "195 ->   \n",
      "196 ->   \n",
      "197 ->   [T]\n",
      "198 ->   \n",
      "199 ->   [T]\n",
      "200 ->   [T]\n",
      "Correct 0 of 200  =  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 200, 0.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label2roman(label):\n",
    "    s = ''\n",
    "    for r in label:\n",
    "        s+=romans[int(r)]\n",
    "        #print(i,'->',s)\n",
    "    return s.strip()    \n",
    "    \n",
    "def check_model(verbose=0,show_training=1):\n",
    "    pred = model.predict(samples)\n",
    "    res = pred.argmax(axis=2)\n",
    "    correct = 0\n",
    "    for i in range(len(pred)):\n",
    "        if(not show_training and i in trainSamples): continue\n",
    "        train=''\n",
    "        if (i + 1) in trainSamples: train='[T]'\n",
    "        txt = label2roman(res[i])\n",
    "        txt_correct = cnv.convert(i + 1)\n",
    "        ok=''\n",
    "        if(txt==txt_correct): \n",
    "            correct+=1\n",
    "            ok = \"[ok]\"\n",
    "        if(verbose==1):\n",
    "            print(i + 1,'->',txt, ok,train)\n",
    "    if verbose==0:\n",
    "        for i in range(5):        \n",
    "            x = random.randrange(DATASET_SIZE)\n",
    "            print(x,'->',label2roman(res[x]))    \n",
    "    print('Correct',correct,'of',len(pred),' = ',(correct/len(pred)))\n",
    "    return correct,len(pred),(correct/len(pred))\n",
    "check_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 100 samples 400 epochs and batch_size= 20\n",
      "Epochs so far 0\n",
      "\n",
      "Epoch 400 - loss = 0.383, loss improvement = 1.222\n",
      "164 -> CLXII\n",
      "140 -> CXXXI\n",
      "106 -> CXI\n",
      "134 -> CXXXI\n",
      "11 -> XI\n",
      "Correct 22 of 200  =  0.11\n",
      "accuracy=11.000%\n",
      "\n",
      "Epoch 800 - loss = 0.304, loss improvement = 0.075\n",
      "24 -> XXVV\n",
      "10 -> XI\n",
      "42 -> XLI\n",
      "159 -> CLVI\n",
      "87 -> LXXXII\n",
      "Correct 34 of 200  =  0.17\n",
      "accuracy=17.000%\n",
      "\n",
      "Epoch 1200 - loss = 0.220, loss improvement = 0.064\n",
      "44 -> XLVV\n",
      "83 -> LXXXIV\n",
      "156 -> CLVI\n",
      "107 -> CVI\n",
      "137 -> CXXXI\n",
      "Correct 45 of 200  =  0.225\n",
      "accuracy=22.500%\n",
      "\n",
      "Epoch 1600 - loss = 0.226, loss improvement =-0.004\n",
      "39 -> XL\n",
      "146 -> CXLVII\n",
      "55 -> LV\n",
      "48 -> LL X\n",
      "181 -> CLXXXI\n",
      "Correct 50 of 200  =  0.25\n",
      "accuracy=25.000%\n",
      "\n",
      "Epoch 2000 - loss = 0.192, loss improvement = 0.022\n",
      "52 -> LI\n",
      "190 -> CXCIII\n",
      "178 -> CLXXXI\n",
      "73 -> LXXIII\n",
      "57 -> LVI\n",
      "Correct 56 of 200  =  0.28\n",
      "accuracy=28.000%\n",
      "\n",
      "Epoch 2400 - loss = 0.154, loss improvement = 0.030\n",
      "68 -> LXXI\n",
      "130 -> CXXXI\n",
      "193 -> CXCII\n",
      "107 -> CVI\n",
      "9 -> XX\n",
      "Correct 59 of 200  =  0.295\n",
      "accuracy=29.500%\n",
      "\n",
      "Epoch 2800 - loss = 0.135, loss improvement = 0.016\n",
      "69 -> LXXI\n",
      "129 -> CXXXI\n",
      "58 -> LIX\n",
      "53 -> LI\n",
      "199 -> CX\n",
      "Correct 74 of 200  =  0.37\n",
      "accuracy=37.000%\n",
      "\n",
      "Epoch 3200 - loss = 0.114, loss improvement = 0.017\n",
      "59 -> LX\n",
      "182 -> CLXXXII\n",
      "181 -> CLXXXI\n",
      "69 -> LXXI\n",
      "5 -> V\n",
      "Correct 73 of 200  =  0.365\n",
      "accuracy=36.500%\n",
      "\n",
      "Epoch 3600 - loss = 0.293, loss improvement =-0.186\n",
      "190 -> CLXXXIX\n",
      "17 -> XVIII\n",
      "52 -> LII\n",
      "186 -> CLXXXI\n",
      "154 -> CLVI\n",
      "Correct 47 of 200  =  0.235\n",
      "accuracy=23.500%\n",
      "\n",
      "Epoch 4000 - loss = 0.076, loss improvement = 0.132\n",
      "72 -> LXXIII\n",
      "152 -> CLIV\n",
      "192 -> CXCIII\n",
      "3 -> IV\n",
      "183 -> CLXXXIV\n",
      "Correct 89 of 200  =  0.445\n",
      "accuracy=44.500%\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 0\n",
    "EPOCHS=400\n",
    "BATCH_SIZE = int(len(trainSamples)/5)\n",
    "print('Training with',len(trainSamples),'samples',EPOCHS,'epochs and batch_size=',BATCH_SIZE)\n",
    "print(\"Epochs so far\",num_epochs)\n",
    "for x in range(10):\n",
    "    H = model.fit(trainSamples, trainLabels, epochs=EPOCHS,verbose=0,batch_size=BATCH_SIZE, validation_data=(testSamples, testLabels))\n",
    "    num_epochs += EPOCHS\n",
    "    print()\n",
    "    print(\"Epoch {} - loss ={:6.3f}, loss improvement ={:6.3f}\".\n",
    "          format(num_epochs,H.history['loss'][-1], H.history['loss'][0]-H.history['loss'][-1]))\n",
    "    pred = model.predict(samples)\n",
    "    res = pred.argmax(axis=2)\n",
    "    c,l,p = check_model()\n",
    "    print(\"accuracy={:6.3f}%\".format(100*p))\n",
    "print(\"Done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzenie modelu i jego zapis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -> I [ok] [T]\n",
      "2 -> II [ok] [T]\n",
      "3 -> II  \n",
      "4 -> IV [ok] [T]\n",
      "5 -> V [ok] [T]\n",
      "6 -> V  \n",
      "7 -> VIII  \n",
      "8 -> VIII [ok] [T]\n",
      "9 -> IX [ok] [T]\n",
      "10 -> XI  \n",
      "11 -> XI [ok] [T]\n",
      "12 -> XI  \n",
      "13 -> XIV  \n",
      "14 -> XIV [ok] [T]\n",
      "15 -> XV [ok] [T]\n",
      "16 -> XV  \n",
      "17 -> XVIII  \n",
      "18 -> XVIII [ok] [T]\n",
      "19 -> XVIII  \n",
      "20 -> XXI  \n",
      "21 -> XXI [ok] [T]\n",
      "22 -> XXII [ok] [T]\n",
      "23 -> XXIV  \n",
      "24 -> XXIV [ok] [T]\n",
      "25 -> XXVI  \n",
      "26 -> XXVI [ok] [T]\n",
      "27 -> XXVI  \n",
      "28 -> XXIX  \n",
      "29 -> XXIX [ok] [T]\n",
      "30 -> XXIX  \n",
      "31 -> XXIII  \n",
      "32 -> XXXIII  \n",
      "33 -> XXXIII [ok] [T]\n",
      "34 -> XXXVII  \n",
      "35 -> XXXV [ok] [T]\n",
      "36 -> XXXV  \n",
      "37 -> XXXVIII  \n",
      "38 -> XXXVIII [ok] [T]\n",
      "39 -> XX VII  \n",
      "40 -> XL [ok] [T]\n",
      "41 -> XLI [ok] [T]\n",
      "42 -> XLI  \n",
      "43 -> XLIV  \n",
      "44 -> XLIV [ok] [T]\n",
      "45 -> XLV [ok] [T]\n",
      "46 -> XLVI [ok] \n",
      "47 -> XLVIII  \n",
      "48 -> XLVIII [ok] [T]\n",
      "49 -> XLIX [ok] [T]\n",
      "50 -> L [ok] [T]\n",
      "51 -> LI [ok] [T]\n",
      "52 -> LII [ok] \n",
      "53 -> LIII [ok] [T]\n",
      "54 -> LIV [ok] [T]\n",
      "55 -> LV [ok] [T]\n",
      "56 -> LV  \n",
      "57 -> LVIII  \n",
      "58 -> LVIII [ok] [T]\n",
      "59 -> LIX [ok] [T]\n",
      "60 -> LX [ok] [T]\n",
      "61 -> LX  \n",
      "62 -> LXIII  \n",
      "63 -> LXIII [ok] [T]\n",
      "64 -> LXIV [ok] [T]\n",
      "65 -> LXV [ok] [T]\n",
      "66 -> LXV  \n",
      "67 -> LXV  \n",
      "68 -> LXX  \n",
      "69 -> LXX  \n",
      "70 -> LXXI  \n",
      "71 -> LXXI [ok] [T]\n",
      "72 -> LXXII [ok] [T]\n",
      "73 -> LXXIII [ok] [T]\n",
      "74 -> LXXV  \n",
      "75 -> LXXV [ok] [T]\n",
      "76 -> LXXV  \n",
      "77 -> LXXV  \n",
      "78 -> LXXVI  \n",
      "79 -> LXXXI  \n",
      "80 -> LXXXI  \n",
      "81 -> LXXXI [ok] [T]\n",
      "82 -> LXXXII [ok] [T]\n",
      "83 -> LXXXIV  \n",
      "84 -> LXXXIV [ok] [T]\n",
      "85 -> LXXXIV  \n",
      "86 -> LXXXIVI  \n",
      "87 -> LXXXVIII  \n",
      "88 -> LXXXVIII [ok] [T]\n",
      "89 -> LXXXIX [ok] [T]\n",
      "90 -> XC [ok] [T]\n",
      "91 -> XCII  \n",
      "92 -> XCII [ok] [T]\n",
      "93 -> XCIII [ok] [T]\n",
      "94 -> XCV  \n",
      "95 -> XCV [ok] [T]\n",
      "96 -> XCV  \n",
      "97 -> XC  \n",
      "98 -> C  \n",
      "99 -> C  \n",
      "100 -> C [ok] [T]\n",
      "101 -> C  \n",
      "102 -> CI  \n",
      "103 -> CII  [T]\n",
      "104 -> CII  [T]\n",
      "105 -> CII  \n",
      "106 -> CVII  [T]\n",
      "107 -> CVII [ok] [T]\n",
      "108 -> CVI  [T]\n",
      "109 -> CVI  [T]\n",
      "110 -> CXI  [T]\n",
      "111 -> CXI [ok] [T]\n",
      "112 -> CXIII  \n",
      "113 -> CXIII [ok] [T]\n",
      "114 -> CXIII  \n",
      "115 -> CXVII  \n",
      "116 -> CXVII  \n",
      "117 -> CXVII [ok] [T]\n",
      "118 -> CXVII  \n",
      "119 -> CXVII  \n",
      "120 -> CXVII  \n",
      "121 -> CXXII  \n",
      "122 -> CXXII [ok] [T]\n",
      "123 -> CXXIV  \n",
      "124 -> CXXIV [ok] [T]\n",
      "125 -> CXXIV  \n",
      "126 -> CXXIV  \n",
      "127 -> CXXI  \n",
      "128 -> CXXX  \n",
      "129 -> CXXX  \n",
      "130 -> CXXX [ok] [T]\n",
      "131 -> CXXXI [ok] [T]\n",
      "132 -> CXXXI  [T]\n",
      "133 -> CXXXII  \n",
      "134 -> CXXXIV [ok] [T]\n",
      "135 -> CXXXI  [T]\n",
      "136 -> CXXXV  \n",
      "137 -> CXXXIX  \n",
      "138 -> CXXXIX  \n",
      "139 -> CXXXIX [ok] [T]\n",
      "140 -> CXXXIX  \n",
      "141 -> CXXXIX  \n",
      "142 -> CXLIII  \n",
      "143 -> CXLIII [ok] [T]\n",
      "144 -> CXLVI  \n",
      "145 -> CXLV [ok] [T]\n",
      "146 -> CXLVI [ok] [T]\n",
      "147 -> CXLVII [ok] [T]\n",
      "148 -> CXLVIII [ok] [T]\n",
      "149 -> CL  \n",
      "150 -> CL [ok] [T]\n",
      "151 -> CLI [ok] \n",
      "152 -> CLII [ok] [T]\n",
      "153 -> CLIV  \n",
      "154 -> CLII  [T]\n",
      "155 -> CLVI  [T]\n",
      "156 -> CLVI [ok] [T]\n",
      "157 -> CLVII [ok] [T]\n",
      "158 -> CLVIII [ok] [T]\n",
      "159 -> CLVIII  \n",
      "160 -> CLXI  \n",
      "161 -> CLXI [ok] [T]\n",
      "162 -> CLXI  \n",
      "163 -> CLXIV  \n",
      "164 -> CLXIV [ok] [T]\n",
      "165 -> CLXIV  \n",
      "166 -> CLXIII  \n",
      "167 -> CLXVII [ok] [T]\n",
      "168 -> CLXVII  [T]\n",
      "169 -> CLXVII  [T]\n",
      "170 -> CLXIII  \n",
      "171 -> CLXXII  \n",
      "172 -> CLXXII [ok] [T]\n",
      "173 -> CLXXII  \n",
      "174 -> CLXXII  \n",
      "175 -> CLXXVI  \n",
      "176 -> CLXXVI [ok] [T]\n",
      "177 -> CLXXVII [ok] [T]\n",
      "178 -> CLXXII  \n",
      "179 -> CLXXIX [ok] [T]\n",
      "180 -> CLXXX [ok] [T]\n",
      "181 -> CLXXXI [ok] [T]\n",
      "182 -> CLXXXII [ok] [T]\n",
      "183 -> CLXXXIV  \n",
      "184 -> CLXXXIV [ok] [T]\n",
      "185 -> CLXXXV [ok] [T]\n",
      "186 -> CLXXXVI [ok] [T]\n",
      "187 -> CLXXXVX  \n",
      "188 -> CLXXXIX  \n",
      "189 -> CLXXXIX [ok] [T]\n",
      "190 -> CLXXXIX  \n",
      "191 -> CXCIII  \n",
      "192 -> CXCIII  \n",
      "193 -> CXCIII [ok] [T]\n",
      "194 -> CXCIV [ok] [T]\n",
      "195 -> CXCIII  \n",
      "196 -> CXCVII  \n",
      "197 -> CXCVII [ok] [T]\n",
      "198 -> CXCIX  \n",
      "199 -> CXC X  [T]\n",
      "200 -> CX  [T]\n",
      "Correct 89 of 200  =  0.445\n"
     ]
    }
   ],
   "source": [
    "check_model(1)\n",
    "model.save('model_number2roman.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzenie działania dla własnej liczby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XI\n"
     ]
    }
   ],
   "source": [
    "input=10\n",
    "x = model.predict(np.array([input]))\n",
    "v = np.argmax(x,axis=2)\n",
    "print(label2roman(v.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
