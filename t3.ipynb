{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importy potrzebnych modułów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pawel\\anaconda3\\envs\\deep\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\pawel\\anaconda3\\envs\\deep\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.preprocessing.label module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.preprocessing. Anything that cannot be imported from sklearn.preprocessing is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics.classification import classification_report, accuracy_score, cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing.label import LabelBinarizer\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.models import Sequential\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odczytanie obrazków, zamiana na rozmiar 64x64, zapis do samples i labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 3670  samples\n",
      "classes {'dandelion', 'tulips', 'roses', 'daisy', 'sunflowers'}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "def load_img(indir):\n",
    "    samples = []\n",
    "    labels = []\n",
    "    for class_dir in os.listdir(indir):\n",
    "        the_class = class_dir\n",
    "        for file in os.listdir(indir+'/'+class_dir):\n",
    "            image = cv2.imread(\"{}/{}/{}\".format(indir,class_dir,file))\n",
    "            image = cv2.resize(image, (64,64))\n",
    "            samples.append(image)\n",
    "            labels.append(the_class)\n",
    "    samples = np.array(samples)\n",
    "    labels = np.array(labels)\n",
    "    return samples,labels\n",
    "samples, labels = load_img('flower_photos')\n",
    "print('loaded',len(samples),' samples')\n",
    "print('classes',set(labels))\n",
    "org_samples = samples\n",
    "org_labels = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utworzenie modelu CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 16)        448       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64, 64, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        4640      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 4,199,968\n",
      "Trainable params: 4,199,936\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "cnnmodel = Sequential()\n",
    "cnnmodel.add(Conv2D(16, (3, 3), padding=\"same\",input_shape=(64,64,3)))\n",
    "cnnmodel.add(BatchNormalization())\n",
    "cnnmodel.add(Activation(\"relu\"))\n",
    "cnnmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnnmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "cnnmodel.add(Activation(\"relu\"))\n",
    "cnnmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnnmodel.add(Dropout(0.25))\n",
    "\n",
    "cnnmodel.add(Flatten())\n",
    "cnnmodel.add(Dense(512))\n",
    "cnnmodel.add(Activation(\"relu\"))\n",
    "\n",
    "cnnmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zmiana typu labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape (3670, 5)\n"
     ]
    }
   ],
   "source": [
    "# one-hot labels\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "print(\"Labels shape\",labels.shape)\n",
    "labels = labels.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przekopiowanie samples do samples2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 3670  samples\n"
     ]
    }
   ],
   "source": [
    "samples2 = copy.deepcopy(org_samples)\n",
    "print('loaded',len(samples2),' samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metody ekstrakcji cech dla samples2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mahotas\n",
    "\n",
    "def fd_hu_moments(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
    "    return feature\n",
    "\n",
    "def fd_haralick(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    haralick = mahotas.features.haralick(gray).mean(axis=0)\n",
    "    return haralick\n",
    "\n",
    "def fd_histogram(image, mask=None):\n",
    "    bins=8\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist  = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stworzenie flat sampli dla modelu Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 3670\n",
      "500 / 3670\n",
      "1000 / 3670\n",
      "1500 / 3670\n",
      "2000 / 3670\n",
      "2500 / 3670\n",
      "3000 / 3670\n",
      "3500 / 3670\n",
      "(3670, 532)\n"
     ]
    }
   ],
   "source": [
    "new_samples2 = []\n",
    "for i,image in enumerate(samples2):\n",
    "    fv_hu_moments = fd_hu_moments(image)\n",
    "    fv_haralick   = fd_haralick(image)\n",
    "    fv_histogram  = fd_histogram(image)\n",
    "    if(i%500==0): print(i,'/',len(samples2))\n",
    "    features = np.hstack([fv_histogram, fv_haralick, fv_hu_moments])\n",
    "    new_samples2.append(features)\n",
    "samples2 = np.array(new_samples2)\n",
    "print(samples2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizacja do przedziału 0 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6241640388357443 42116.99917305574\n",
      "0.0 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "print(np.min(samples2),np.max(samples2))\n",
    "samples2 = scaler.fit_transform(samples2)\n",
    "print(np.min(samples2),np.max(samples2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utworzenie modelu Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 250)               133250    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 250)               62750     \n",
      "=================================================================\n",
      "Total params: 196,000\n",
      "Trainable params: 196,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_model = Sequential()\n",
    "dense_model.add(Dense(250, input_dim=532, activation='relu'))\n",
    "dense_model.add(Dense(250, activation='relu'))\n",
    "\n",
    "dense_model.summary()\n",
    "dense_model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konkatenacja modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv2d_input (InputLayer)       [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 16)   448         conv2d_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 16)   64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 16)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 16)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 32)   4640        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 32)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 16, 16, 32)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 8192)         0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1_input (InputLayer)      [(None, 532)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          4194816     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 250)          133250      dense_1_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 250)          62750       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 762)          0           activation_2[0][0]               \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           12208       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 5)            85          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,408,261\n",
      "Trainable params: 4,408,229\n",
      "Non-trainable params: 32\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "combined = concatenate([cnnmodel.output, dense_model.output])\n",
    "combined = Dense(16, activation=\"sigmoid\")(combined)\n",
    "combined = Dense(labels.shape[1], activation=\"sigmoid\")(combined)\n",
    "\n",
    "model = Model(inputs=[cnnmodel.input, dense_model.input], outputs=combined)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenowanie nowo utworzonego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3670 samples\n",
      "Epoch 1/20\n",
      "3670/3670 [==============================] - 11s 3ms/sample - loss: 1.5151 - accuracy: 0.3801\n",
      "Epoch 2/20\n",
      "3670/3670 [==============================] - 10s 3ms/sample - loss: 1.4182 - accuracy: 0.4826\n",
      "Epoch 3/20\n",
      "3670/3670 [==============================] - 11s 3ms/sample - loss: 1.3197 - accuracy: 0.5572\n",
      "Epoch 4/20\n",
      "3670/3670 [==============================] - 10s 3ms/sample - loss: 1.2265 - accuracy: 0.6019\n",
      "Epoch 5/20\n",
      "3670/3670 [==============================] - 10s 3ms/sample - loss: 1.1214 - accuracy: 0.6657\n",
      "Epoch 6/20\n",
      "3670/3670 [==============================] - 10s 3ms/sample - loss: 1.0214 - accuracy: 0.7153\n",
      "Epoch 7/20\n",
      "3670/3670 [==============================] - 10s 3ms/sample - loss: 0.9032 - accuracy: 0.7755\n",
      "Epoch 8/20\n",
      "3670/3670 [==============================] - 10s 3ms/sample - loss: 0.7914 - accuracy: 0.8297\n",
      "Epoch 9/20\n",
      "3670/3670 [==============================] - 10s 3ms/sample - loss: 0.6885 - accuracy: 0.8736\n",
      "Epoch 10/20\n",
      "3670/3670 [==============================] - 10s 3ms/sample - loss: 0.5942 - accuracy: 0.9057\n",
      "Epoch 11/20\n",
      "3670/3670 [==============================] - 10s 3ms/sample - loss: 0.5044 - accuracy: 0.9425\n",
      "Epoch 12/20\n",
      "3670/3670 [==============================] - 10s 3ms/sample - loss: 0.4453 - accuracy: 0.9523\n",
      "Epoch 13/20\n",
      "3670/3670 [==============================] - 10s 3ms/sample - loss: 0.3768 - accuracy: 0.9635\n",
      "Epoch 14/20\n",
      "3670/3670 [==============================] - 10s 3ms/sample - loss: 0.3115 - accuracy: 0.9736\n",
      "Epoch 15/20\n",
      "3670/3670 [==============================] - 10s 3ms/sample - loss: 0.2561 - accuracy: 0.9839\n",
      "Epoch 16/20\n",
      "3670/3670 [==============================] - 10s 3ms/sample - loss: 0.2142 - accuracy: 0.9869\n",
      "Epoch 17/20\n",
      "3670/3670 [==============================] - 10s 3ms/sample - loss: 0.1880 - accuracy: 0.9891\n",
      "Epoch 18/20\n",
      "3670/3670 [==============================] - 10s 3ms/sample - loss: 0.1624 - accuracy: 0.9943\n",
      "Epoch 19/20\n",
      "3670/3670 [==============================] - 10s 3ms/sample - loss: 0.1380 - accuracy: 0.9965\n",
      "Epoch 20/20\n",
      "3670/3670 [==============================] - 10s 3ms/sample - loss: 0.1210 - accuracy: 0.9973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16ecef26f88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "BATCH=100\n",
    "model.fit([samples,samples2], labels, batch_size=BATCH, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osiągnięte wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[633   0   0   0   0]\n",
      " [  0 896   0   2   0]\n",
      " [  0   1 638   0   2]\n",
      " [  0   0   0 699   0]\n",
      " [  0   0   0   0 799]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       633\n",
      "           1       1.00      1.00      1.00       898\n",
      "           2       1.00      1.00      1.00       641\n",
      "           3       1.00      1.00      1.00       699\n",
      "           4       1.00      1.00      1.00       799\n",
      "\n",
      "    accuracy                           1.00      3670\n",
      "   macro avg       1.00      1.00      1.00      3670\n",
      "weighted avg       1.00      1.00      1.00      3670\n",
      "\n",
      "Accuracy: 1.00\n",
      "Cohen's Kappa 1.00\n"
     ]
    }
   ],
   "source": [
    "results = model.predict([samples,samples2])\n",
    "print(confusion_matrix(labels.argmax(axis=1), results.argmax(axis=1)))\n",
    "print(classification_report(labels.argmax(axis=1), results.argmax(axis=1)))\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(labels.argmax(axis=1), results.argmax(axis=1))))\n",
    "print(\"Cohen's Kappa {:.2f}\".format(cohen_kappa_score(labels.argmax(axis=1), results.argmax(axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
